"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import flyteidl.core.catalog_pb2
import flyteidl.core.compiler_pb2
import flyteidl.core.execution_pb2
import flyteidl.core.identifier_pb2
import flyteidl.core.literals_pb2
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import google.protobuf.struct_pb2
import google.protobuf.timestamp_pb2
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class WorkflowExecutionEvent(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    EXECUTION_ID_FIELD_NUMBER: builtins.int
    PRODUCER_ID_FIELD_NUMBER: builtins.int
    PHASE_FIELD_NUMBER: builtins.int
    OCCURRED_AT_FIELD_NUMBER: builtins.int
    OUTPUT_URI_FIELD_NUMBER: builtins.int
    ERROR_FIELD_NUMBER: builtins.int
    OUTPUT_DATA_FIELD_NUMBER: builtins.int
    @property
    def execution_id(self) -> flyteidl.core.identifier_pb2.WorkflowExecutionIdentifier:
        """Workflow execution id"""
        pass
    producer_id: typing.Text = ...
    """the id of the originator (Propeller) of the event"""

    phase: flyteidl.core.execution_pb2.WorkflowExecution.Phase.V = ...
    @property
    def occurred_at(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """This timestamp represents when the original event occurred, it is generated
        by the executor of the workflow.
        """
        pass
    output_uri: typing.Text = ...
    """URL to the output of the execution, it encodes all the information
    including Cloud source provider. ie., s3://...
    """

    @property
    def error(self) -> flyteidl.core.execution_pb2.ExecutionError:
        """Error information for the execution"""
        pass
    @property
    def output_data(self) -> flyteidl.core.literals_pb2.LiteralMap:
        """Raw output data produced by this workflow execution."""
        pass
    def __init__(self,
        *,
        execution_id : typing.Optional[flyteidl.core.identifier_pb2.WorkflowExecutionIdentifier] = ...,
        producer_id : typing.Text = ...,
        phase : flyteidl.core.execution_pb2.WorkflowExecution.Phase.V = ...,
        occurred_at : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        output_uri : typing.Text = ...,
        error : typing.Optional[flyteidl.core.execution_pb2.ExecutionError] = ...,
        output_data : typing.Optional[flyteidl.core.literals_pb2.LiteralMap] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"error",b"error",u"execution_id",b"execution_id",u"occurred_at",b"occurred_at",u"output_data",b"output_data",u"output_result",b"output_result",u"output_uri",b"output_uri"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"error",b"error",u"execution_id",b"execution_id",u"occurred_at",b"occurred_at",u"output_data",b"output_data",u"output_result",b"output_result",u"output_uri",b"output_uri",u"phase",b"phase",u"producer_id",b"producer_id"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal[u"output_result",b"output_result"]) -> typing.Optional[typing_extensions.Literal["output_uri","error","output_data"]]: ...
global___WorkflowExecutionEvent = WorkflowExecutionEvent

class NodeExecutionEvent(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ID_FIELD_NUMBER: builtins.int
    PRODUCER_ID_FIELD_NUMBER: builtins.int
    PHASE_FIELD_NUMBER: builtins.int
    OCCURRED_AT_FIELD_NUMBER: builtins.int
    INPUT_URI_FIELD_NUMBER: builtins.int
    OUTPUT_URI_FIELD_NUMBER: builtins.int
    ERROR_FIELD_NUMBER: builtins.int
    OUTPUT_DATA_FIELD_NUMBER: builtins.int
    WORKFLOW_NODE_METADATA_FIELD_NUMBER: builtins.int
    TASK_NODE_METADATA_FIELD_NUMBER: builtins.int
    PARENT_TASK_METADATA_FIELD_NUMBER: builtins.int
    PARENT_NODE_METADATA_FIELD_NUMBER: builtins.int
    RETRY_GROUP_FIELD_NUMBER: builtins.int
    SPEC_NODE_ID_FIELD_NUMBER: builtins.int
    NODE_NAME_FIELD_NUMBER: builtins.int
    @property
    def id(self) -> flyteidl.core.identifier_pb2.NodeExecutionIdentifier:
        """Unique identifier for this node execution"""
        pass
    producer_id: typing.Text = ...
    """the id of the originator (Propeller) of the event"""

    phase: flyteidl.core.execution_pb2.NodeExecution.Phase.V = ...
    @property
    def occurred_at(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """This timestamp represents when the original event occurred, it is generated
        by the executor of the node.
        """
        pass
    input_uri: typing.Text = ...
    output_uri: typing.Text = ...
    """URL to the output of the execution, it encodes all the information
    including Cloud source provider. ie., s3://...
    """

    @property
    def error(self) -> flyteidl.core.execution_pb2.ExecutionError:
        """Error information for the execution"""
        pass
    @property
    def output_data(self) -> flyteidl.core.literals_pb2.LiteralMap:
        """Raw output data produced by this node execution."""
        pass
    @property
    def workflow_node_metadata(self) -> global___WorkflowNodeMetadata: ...
    @property
    def task_node_metadata(self) -> global___TaskNodeMetadata: ...
    @property
    def parent_task_metadata(self) -> global___ParentTaskExecutionMetadata:
        """[To be deprecated] Specifies which task (if any) launched this node."""
        pass
    @property
    def parent_node_metadata(self) -> global___ParentNodeExecutionMetadata:
        """Specifies the parent node of the current node execution. Node executions at level zero will not have a parent node."""
        pass
    retry_group: typing.Text = ...
    """Retry group to indicate grouping of nodes by retries"""

    spec_node_id: typing.Text = ...
    """Identifier of the node in the original workflow/graph
    This maps to value of WorkflowTemplate.nodes[X].id
    """

    node_name: typing.Text = ...
    """Friendly readable name for the node"""

    def __init__(self,
        *,
        id : typing.Optional[flyteidl.core.identifier_pb2.NodeExecutionIdentifier] = ...,
        producer_id : typing.Text = ...,
        phase : flyteidl.core.execution_pb2.NodeExecution.Phase.V = ...,
        occurred_at : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        input_uri : typing.Text = ...,
        output_uri : typing.Text = ...,
        error : typing.Optional[flyteidl.core.execution_pb2.ExecutionError] = ...,
        output_data : typing.Optional[flyteidl.core.literals_pb2.LiteralMap] = ...,
        workflow_node_metadata : typing.Optional[global___WorkflowNodeMetadata] = ...,
        task_node_metadata : typing.Optional[global___TaskNodeMetadata] = ...,
        parent_task_metadata : typing.Optional[global___ParentTaskExecutionMetadata] = ...,
        parent_node_metadata : typing.Optional[global___ParentNodeExecutionMetadata] = ...,
        retry_group : typing.Text = ...,
        spec_node_id : typing.Text = ...,
        node_name : typing.Text = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"error",b"error",u"id",b"id",u"occurred_at",b"occurred_at",u"output_data",b"output_data",u"output_result",b"output_result",u"output_uri",b"output_uri",u"parent_node_metadata",b"parent_node_metadata",u"parent_task_metadata",b"parent_task_metadata",u"target_metadata",b"target_metadata",u"task_node_metadata",b"task_node_metadata",u"workflow_node_metadata",b"workflow_node_metadata"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"error",b"error",u"id",b"id",u"input_uri",b"input_uri",u"node_name",b"node_name",u"occurred_at",b"occurred_at",u"output_data",b"output_data",u"output_result",b"output_result",u"output_uri",b"output_uri",u"parent_node_metadata",b"parent_node_metadata",u"parent_task_metadata",b"parent_task_metadata",u"phase",b"phase",u"producer_id",b"producer_id",u"retry_group",b"retry_group",u"spec_node_id",b"spec_node_id",u"target_metadata",b"target_metadata",u"task_node_metadata",b"task_node_metadata",u"workflow_node_metadata",b"workflow_node_metadata"]) -> None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal[u"output_result",b"output_result"]) -> typing.Optional[typing_extensions.Literal["output_uri","error","output_data"]]: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal[u"target_metadata",b"target_metadata"]) -> typing.Optional[typing_extensions.Literal["workflow_node_metadata","task_node_metadata"]]: ...
global___NodeExecutionEvent = NodeExecutionEvent

class WorkflowNodeMetadata(google.protobuf.message.Message):
    """For Workflow Nodes we need to send information about the workflow that's launched"""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    EXECUTION_ID_FIELD_NUMBER: builtins.int
    @property
    def execution_id(self) -> flyteidl.core.identifier_pb2.WorkflowExecutionIdentifier: ...
    def __init__(self,
        *,
        execution_id : typing.Optional[flyteidl.core.identifier_pb2.WorkflowExecutionIdentifier] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"execution_id",b"execution_id"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"execution_id",b"execution_id"]) -> None: ...
global___WorkflowNodeMetadata = WorkflowNodeMetadata

class TaskNodeMetadata(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    CACHE_STATUS_FIELD_NUMBER: builtins.int
    CATALOG_KEY_FIELD_NUMBER: builtins.int
    DYNAMIC_WORKFLOW_FIELD_NUMBER: builtins.int
    cache_status: flyteidl.core.catalog_pb2.CatalogCacheStatus.V = ...
    """Captures the status of caching for this execution."""

    @property
    def catalog_key(self) -> flyteidl.core.catalog_pb2.CatalogMetadata:
        """This structure carries the catalog artifact information"""
        pass
    @property
    def dynamic_workflow(self) -> global___DynamicWorkflowNodeMetadata:
        """In the case this task launched a dynamic workflow we capture its structure here."""
        pass
    def __init__(self,
        *,
        cache_status : flyteidl.core.catalog_pb2.CatalogCacheStatus.V = ...,
        catalog_key : typing.Optional[flyteidl.core.catalog_pb2.CatalogMetadata] = ...,
        dynamic_workflow : typing.Optional[global___DynamicWorkflowNodeMetadata] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"catalog_key",b"catalog_key",u"dynamic_workflow",b"dynamic_workflow"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"cache_status",b"cache_status",u"catalog_key",b"catalog_key",u"dynamic_workflow",b"dynamic_workflow"]) -> None: ...
global___TaskNodeMetadata = TaskNodeMetadata

class DynamicWorkflowNodeMetadata(google.protobuf.message.Message):
    """For dynamic workflow nodes we send information about the dynamic workflow definition that gets generated."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ID_FIELD_NUMBER: builtins.int
    COMPILED_WORKFLOW_FIELD_NUMBER: builtins.int
    @property
    def id(self) -> flyteidl.core.identifier_pb2.Identifier:
        """id represents the unique identifier of the workflow."""
        pass
    @property
    def compiled_workflow(self) -> flyteidl.core.compiler_pb2.CompiledWorkflowClosure:
        """Represents the compiled representation of the embedded dynamic workflow."""
        pass
    def __init__(self,
        *,
        id : typing.Optional[flyteidl.core.identifier_pb2.Identifier] = ...,
        compiled_workflow : typing.Optional[flyteidl.core.compiler_pb2.CompiledWorkflowClosure] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"compiled_workflow",b"compiled_workflow",u"id",b"id"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"compiled_workflow",b"compiled_workflow",u"id",b"id"]) -> None: ...
global___DynamicWorkflowNodeMetadata = DynamicWorkflowNodeMetadata

class ParentTaskExecutionMetadata(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ID_FIELD_NUMBER: builtins.int
    @property
    def id(self) -> flyteidl.core.identifier_pb2.TaskExecutionIdentifier: ...
    def __init__(self,
        *,
        id : typing.Optional[flyteidl.core.identifier_pb2.TaskExecutionIdentifier] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"id",b"id"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"id",b"id"]) -> None: ...
global___ParentTaskExecutionMetadata = ParentTaskExecutionMetadata

class ParentNodeExecutionMetadata(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    NODE_ID_FIELD_NUMBER: builtins.int
    node_id: typing.Text = ...
    """Unique identifier of the parent node id within the execution
    This is value of core.NodeExecutionIdentifier.node_id of the parent node
    """

    def __init__(self,
        *,
        node_id : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"node_id",b"node_id"]) -> None: ...
global___ParentNodeExecutionMetadata = ParentNodeExecutionMetadata

class TaskExecutionEvent(google.protobuf.message.Message):
    """Plugin specific execution event information. For tasks like Python, Hive, Spark, DynamicJob."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    TASK_ID_FIELD_NUMBER: builtins.int
    PARENT_NODE_EXECUTION_ID_FIELD_NUMBER: builtins.int
    RETRY_ATTEMPT_FIELD_NUMBER: builtins.int
    PHASE_FIELD_NUMBER: builtins.int
    PRODUCER_ID_FIELD_NUMBER: builtins.int
    LOGS_FIELD_NUMBER: builtins.int
    OCCURRED_AT_FIELD_NUMBER: builtins.int
    INPUT_URI_FIELD_NUMBER: builtins.int
    OUTPUT_URI_FIELD_NUMBER: builtins.int
    ERROR_FIELD_NUMBER: builtins.int
    OUTPUT_DATA_FIELD_NUMBER: builtins.int
    CUSTOM_INFO_FIELD_NUMBER: builtins.int
    PHASE_VERSION_FIELD_NUMBER: builtins.int
    REASON_FIELD_NUMBER: builtins.int
    TASK_TYPE_FIELD_NUMBER: builtins.int
    METADATA_FIELD_NUMBER: builtins.int
    @property
    def task_id(self) -> flyteidl.core.identifier_pb2.Identifier:
        """ID of the task. In combination with the retryAttempt this will indicate
        the task execution uniquely for a given parent node execution.
        """
        pass
    @property
    def parent_node_execution_id(self) -> flyteidl.core.identifier_pb2.NodeExecutionIdentifier:
        """A task execution is always kicked off by a node execution, the event consumer
        will use the parent_id to relate the task to it's parent node execution
        """
        pass
    retry_attempt: builtins.int = ...
    """retry attempt number for this task, ie., 2 for the second attempt"""

    phase: flyteidl.core.execution_pb2.TaskExecution.Phase.V = ...
    """Phase associated with the event"""

    producer_id: typing.Text = ...
    """id of the process that sent this event, mainly for trace debugging"""

    @property
    def logs(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[flyteidl.core.execution_pb2.TaskLog]:
        """log information for the task execution"""
        pass
    @property
    def occurred_at(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """This timestamp represents when the original event occurred, it is generated
        by the executor of the task.
        """
        pass
    input_uri: typing.Text = ...
    """URI of the input file, it encodes all the information
    including Cloud source provider. ie., s3://...
    """

    output_uri: typing.Text = ...
    """URI to the output of the execution, it will be in a format that encodes all the information
    including Cloud source provider. ie., s3://...
    """

    @property
    def error(self) -> flyteidl.core.execution_pb2.ExecutionError:
        """Error information for the execution"""
        pass
    @property
    def output_data(self) -> flyteidl.core.literals_pb2.LiteralMap:
        """Raw output data produced by this task execution."""
        pass
    @property
    def custom_info(self) -> google.protobuf.struct_pb2.Struct:
        """Custom data that the task plugin sends back. This is extensible to allow various plugins in the system."""
        pass
    phase_version: builtins.int = ...
    """Some phases, like RUNNING, can send multiple events with changed metadata (new logs, additional custom_info, etc)
    that should be recorded regardless of the lack of phase change.
    The version field should be incremented when metadata changes across the duration of an individual phase.
    """

    reason: typing.Text = ...
    """An optional explanation for the phase transition."""

    task_type: typing.Text = ...
    """A predefined yet extensible Task type identifier. If the task definition is already registered in flyte admin
    this type will be identical, but not all task executions necessarily use pre-registered definitions and this
    type is useful to render the task in the UI, filter task executions, etc.
    """

    @property
    def metadata(self) -> global___TaskExecutionMetadata:
        """Metadata around how a task was executed."""
        pass
    def __init__(self,
        *,
        task_id : typing.Optional[flyteidl.core.identifier_pb2.Identifier] = ...,
        parent_node_execution_id : typing.Optional[flyteidl.core.identifier_pb2.NodeExecutionIdentifier] = ...,
        retry_attempt : builtins.int = ...,
        phase : flyteidl.core.execution_pb2.TaskExecution.Phase.V = ...,
        producer_id : typing.Text = ...,
        logs : typing.Optional[typing.Iterable[flyteidl.core.execution_pb2.TaskLog]] = ...,
        occurred_at : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        input_uri : typing.Text = ...,
        output_uri : typing.Text = ...,
        error : typing.Optional[flyteidl.core.execution_pb2.ExecutionError] = ...,
        output_data : typing.Optional[flyteidl.core.literals_pb2.LiteralMap] = ...,
        custom_info : typing.Optional[google.protobuf.struct_pb2.Struct] = ...,
        phase_version : builtins.int = ...,
        reason : typing.Text = ...,
        task_type : typing.Text = ...,
        metadata : typing.Optional[global___TaskExecutionMetadata] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"custom_info",b"custom_info",u"error",b"error",u"metadata",b"metadata",u"occurred_at",b"occurred_at",u"output_data",b"output_data",u"output_result",b"output_result",u"output_uri",b"output_uri",u"parent_node_execution_id",b"parent_node_execution_id",u"task_id",b"task_id"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"custom_info",b"custom_info",u"error",b"error",u"input_uri",b"input_uri",u"logs",b"logs",u"metadata",b"metadata",u"occurred_at",b"occurred_at",u"output_data",b"output_data",u"output_result",b"output_result",u"output_uri",b"output_uri",u"parent_node_execution_id",b"parent_node_execution_id",u"phase",b"phase",u"phase_version",b"phase_version",u"producer_id",b"producer_id",u"reason",b"reason",u"retry_attempt",b"retry_attempt",u"task_id",b"task_id",u"task_type",b"task_type"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal[u"output_result",b"output_result"]) -> typing.Optional[typing_extensions.Literal["output_uri","error","output_data"]]: ...
global___TaskExecutionEvent = TaskExecutionEvent

class ExternalResourceInfo(google.protobuf.message.Message):
    """This message contains metadata about external resources produced or used by a specific task execution."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    EXTERNAL_ID_FIELD_NUMBER: builtins.int
    external_id: typing.Text = ...
    """Identifier for an external resource created by this task execution, for example Qubole query ID or presto query ids."""

    def __init__(self,
        *,
        external_id : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"external_id",b"external_id"]) -> None: ...
global___ExternalResourceInfo = ExternalResourceInfo

class ResourcePoolInfo(google.protobuf.message.Message):
    """This message holds task execution metadata specific to resource allocation used to manage concurrent
    executions for a project namespace.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ALLOCATION_TOKEN_FIELD_NUMBER: builtins.int
    NAMESPACE_FIELD_NUMBER: builtins.int
    allocation_token: typing.Text = ...
    """Unique resource ID used to identify this execution when allocating a token."""

    namespace: typing.Text = ...
    """Namespace under which this task execution requested an allocation token."""

    def __init__(self,
        *,
        allocation_token : typing.Text = ...,
        namespace : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"allocation_token",b"allocation_token",u"namespace",b"namespace"]) -> None: ...
global___ResourcePoolInfo = ResourcePoolInfo

class TaskExecutionMetadata(google.protobuf.message.Message):
    """Holds metadata around how a task was executed.
    As a task transitions across event phases during execution some attributes, such its generated name, generated external resources,
    and more may grow in size but not change necessarily based on the phase transition that sparked the event update.
    Metadata is a container for these attributes across the task execution lifecycle.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class InstanceClass(_InstanceClass, metaclass=_InstanceClassEnumTypeWrapper):
        """Includes the broad category of machine used for this specific task execution."""
        pass
    class _InstanceClass:
        V = typing.NewType('V', builtins.int)
    class _InstanceClassEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_InstanceClass.V], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        DEFAULT = TaskExecutionMetadata.InstanceClass.V(0)
        """The default instance class configured for the flyte application platform."""

        INTERRUPTIBLE = TaskExecutionMetadata.InstanceClass.V(1)
        """The instance class configured for interruptible tasks."""


    DEFAULT = TaskExecutionMetadata.InstanceClass.V(0)
    """The default instance class configured for the flyte application platform."""

    INTERRUPTIBLE = TaskExecutionMetadata.InstanceClass.V(1)
    """The instance class configured for interruptible tasks."""


    GENERATED_NAME_FIELD_NUMBER: builtins.int
    EXTERNAL_RESOURCES_FIELD_NUMBER: builtins.int
    RESOURCE_POOL_INFO_FIELD_NUMBER: builtins.int
    PLUGIN_IDENTIFIER_FIELD_NUMBER: builtins.int
    INSTANCE_CLASS_FIELD_NUMBER: builtins.int
    generated_name: typing.Text = ...
    """Unique, generated name for this task execution used by the backend."""

    @property
    def external_resources(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ExternalResourceInfo]:
        """Additional data on external resources on other back-ends or platforms (e.g. Hive, Qubole, etc) launched by this task execution."""
        pass
    @property
    def resource_pool_info(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ResourcePoolInfo]:
        """Includes additional data on concurrent resource management used during execution..
        This is a repeated field because a plugin can request multiple resource allocations during execution.
        """
        pass
    plugin_identifier: typing.Text = ...
    """The identifier of the plugin used to execute this task."""

    instance_class: global___TaskExecutionMetadata.InstanceClass.V = ...
    def __init__(self,
        *,
        generated_name : typing.Text = ...,
        external_resources : typing.Optional[typing.Iterable[global___ExternalResourceInfo]] = ...,
        resource_pool_info : typing.Optional[typing.Iterable[global___ResourcePoolInfo]] = ...,
        plugin_identifier : typing.Text = ...,
        instance_class : global___TaskExecutionMetadata.InstanceClass.V = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"external_resources",b"external_resources",u"generated_name",b"generated_name",u"instance_class",b"instance_class",u"plugin_identifier",b"plugin_identifier",u"resource_pool_info",b"resource_pool_info"]) -> None: ...
global___TaskExecutionMetadata = TaskExecutionMetadata
