"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import flyteidl.core.condition_pb2
import flyteidl.core.execution_pb2
import flyteidl.core.identifier_pb2
import flyteidl.core.interface_pb2
import flyteidl.core.literals_pb2
import flyteidl.core.tasks_pb2
import flyteidl.core.types_pb2
import google.protobuf.descriptor
import google.protobuf.duration_pb2
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class IfBlock(google.protobuf.message.Message):
    """Defines a condition and the execution unit that should be executed if the condition is satisfied."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    CONDITION_FIELD_NUMBER: builtins.int
    THEN_NODE_FIELD_NUMBER: builtins.int
    @property
    def condition(self) -> flyteidl.core.condition_pb2.BooleanExpression: ...
    @property
    def then_node(self) -> global___Node: ...
    def __init__(self,
        *,
        condition : typing.Optional[flyteidl.core.condition_pb2.BooleanExpression] = ...,
        then_node : typing.Optional[global___Node] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"condition",b"condition",u"then_node",b"then_node"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"condition",b"condition",u"then_node",b"then_node"]) -> None: ...
global___IfBlock = IfBlock

class IfElseBlock(google.protobuf.message.Message):
    """Defines a series of if/else blocks. The first branch whose condition evaluates to true is the one to execute.
    If no conditions were satisfied, the else_node or the error will execute.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    CASE_FIELD_NUMBER: builtins.int
    OTHER_FIELD_NUMBER: builtins.int
    ELSE_NODE_FIELD_NUMBER: builtins.int
    ERROR_FIELD_NUMBER: builtins.int
    @property
    def case(self) -> global___IfBlock:
        """+required. First condition to evaluate."""
        pass
    @property
    def other(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___IfBlock]:
        """+optional. Additional branches to evaluate."""
        pass
    @property
    def else_node(self) -> global___Node:
        """The node to execute in case none of the branches were taken."""
        pass
    @property
    def error(self) -> flyteidl.core.types_pb2.Error:
        """An error to throw in case none of the branches were taken."""
        pass
    def __init__(self,
        *,
        case : typing.Optional[global___IfBlock] = ...,
        other : typing.Optional[typing.Iterable[global___IfBlock]] = ...,
        else_node : typing.Optional[global___Node] = ...,
        error : typing.Optional[flyteidl.core.types_pb2.Error] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"case",b"case",u"default",b"default",u"else_node",b"else_node",u"error",b"error"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"case",b"case",u"default",b"default",u"else_node",b"else_node",u"error",b"error",u"other",b"other"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal[u"default",b"default"]) -> typing.Optional[typing_extensions.Literal["else_node","error"]]: ...
global___IfElseBlock = IfElseBlock

class BranchNode(google.protobuf.message.Message):
    """BranchNode is a special node that alter the flow of the workflow graph. It allows the control flow to branch at
    runtime based on a series of conditions that get evaluated on various parameters (e.g. inputs, primitives).
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    IF_ELSE_FIELD_NUMBER: builtins.int
    @property
    def if_else(self) -> global___IfElseBlock:
        """+required"""
        pass
    def __init__(self,
        *,
        if_else : typing.Optional[global___IfElseBlock] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"if_else",b"if_else"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"if_else",b"if_else"]) -> None: ...
global___BranchNode = BranchNode

class TaskNode(google.protobuf.message.Message):
    """Refers to the task that the Node is to execute."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    REFERENCE_ID_FIELD_NUMBER: builtins.int
    OVERRIDES_FIELD_NUMBER: builtins.int
    @property
    def reference_id(self) -> flyteidl.core.identifier_pb2.Identifier:
        """A globally unique identifier for the task."""
        pass
    @property
    def overrides(self) -> global___TaskNodeOverrides:
        """Optional overrides applied at task execution time."""
        pass
    def __init__(self,
        *,
        reference_id : typing.Optional[flyteidl.core.identifier_pb2.Identifier] = ...,
        overrides : typing.Optional[global___TaskNodeOverrides] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"overrides",b"overrides",u"reference",b"reference",u"reference_id",b"reference_id"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"overrides",b"overrides",u"reference",b"reference",u"reference_id",b"reference_id"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal[u"reference",b"reference"]) -> typing.Optional[typing_extensions.Literal["reference_id"]]: ...
global___TaskNode = TaskNode

class WorkflowNode(google.protobuf.message.Message):
    """Refers to a the workflow the node is to execute."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    LAUNCHPLAN_REF_FIELD_NUMBER: builtins.int
    SUB_WORKFLOW_REF_FIELD_NUMBER: builtins.int
    @property
    def launchplan_ref(self) -> flyteidl.core.identifier_pb2.Identifier:
        """A globally unique identifier for the launch plan."""
        pass
    @property
    def sub_workflow_ref(self) -> flyteidl.core.identifier_pb2.Identifier:
        """Reference to a subworkflow, that should be defined with the compiler context"""
        pass
    def __init__(self,
        *,
        launchplan_ref : typing.Optional[flyteidl.core.identifier_pb2.Identifier] = ...,
        sub_workflow_ref : typing.Optional[flyteidl.core.identifier_pb2.Identifier] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"launchplan_ref",b"launchplan_ref",u"reference",b"reference",u"sub_workflow_ref",b"sub_workflow_ref"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"launchplan_ref",b"launchplan_ref",u"reference",b"reference",u"sub_workflow_ref",b"sub_workflow_ref"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal[u"reference",b"reference"]) -> typing.Optional[typing_extensions.Literal["launchplan_ref","sub_workflow_ref"]]: ...
global___WorkflowNode = WorkflowNode

class NodeMetadata(google.protobuf.message.Message):
    """Defines extra information about the Node."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    NAME_FIELD_NUMBER: builtins.int
    TIMEOUT_FIELD_NUMBER: builtins.int
    RETRIES_FIELD_NUMBER: builtins.int
    INTERRUPTIBLE_FIELD_NUMBER: builtins.int
    name: typing.Text = ...
    """A friendly name for the Node"""

    @property
    def timeout(self) -> google.protobuf.duration_pb2.Duration:
        """The overall timeout of a task."""
        pass
    @property
    def retries(self) -> flyteidl.core.literals_pb2.RetryStrategy:
        """Number of retries per task."""
        pass
    interruptible: builtins.bool = ...
    def __init__(self,
        *,
        name : typing.Text = ...,
        timeout : typing.Optional[google.protobuf.duration_pb2.Duration] = ...,
        retries : typing.Optional[flyteidl.core.literals_pb2.RetryStrategy] = ...,
        interruptible : builtins.bool = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"interruptible",b"interruptible",u"interruptible_value",b"interruptible_value",u"retries",b"retries",u"timeout",b"timeout"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"interruptible",b"interruptible",u"interruptible_value",b"interruptible_value",u"name",b"name",u"retries",b"retries",u"timeout",b"timeout"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal[u"interruptible_value",b"interruptible_value"]) -> typing.Optional[typing_extensions.Literal["interruptible"]]: ...
global___NodeMetadata = NodeMetadata

class Alias(google.protobuf.message.Message):
    """Links a variable to an alias."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    VAR_FIELD_NUMBER: builtins.int
    ALIAS_FIELD_NUMBER: builtins.int
    var: typing.Text = ...
    """Must match one of the output variable names on a node."""

    alias: typing.Text = ...
    """A workflow-level unique alias that downstream nodes can refer to in their input."""

    def __init__(self,
        *,
        var : typing.Text = ...,
        alias : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"alias",b"alias",u"var",b"var"]) -> None: ...
global___Alias = Alias

class Node(google.protobuf.message.Message):
    """A Workflow graph Node. One unit of execution in the graph. Each node can be linked to a Task, a Workflow or a branch
    node.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ID_FIELD_NUMBER: builtins.int
    METADATA_FIELD_NUMBER: builtins.int
    INPUTS_FIELD_NUMBER: builtins.int
    UPSTREAM_NODE_IDS_FIELD_NUMBER: builtins.int
    OUTPUT_ALIASES_FIELD_NUMBER: builtins.int
    TASK_NODE_FIELD_NUMBER: builtins.int
    WORKFLOW_NODE_FIELD_NUMBER: builtins.int
    BRANCH_NODE_FIELD_NUMBER: builtins.int
    id: typing.Text = ...
    """A workflow-level unique identifier that identifies this node in the workflow. "inputs" and "outputs" are reserved
    node ids that cannot be used by other nodes.
    """

    @property
    def metadata(self) -> global___NodeMetadata:
        """Extra metadata about the node."""
        pass
    @property
    def inputs(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[flyteidl.core.literals_pb2.Binding]:
        """Specifies how to bind the underlying interface's inputs. All required inputs specified in the underlying interface
        must be fulfilled.
        """
        pass
    @property
    def upstream_node_ids(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """+optional Specifies execution dependency for this node ensuring it will only get scheduled to run after all its
        upstream nodes have completed. This node will have an implicit dependency on any node that appears in inputs
        field.
        """
        pass
    @property
    def output_aliases(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Alias]:
        """+optional. A node can define aliases for a subset of its outputs. This is particularly useful if different nodes
        need to conform to the same interface (e.g. all branches in a branch node). Downstream nodes must refer to this
        nodes outputs using the alias if one's specified.
        """
        pass
    @property
    def task_node(self) -> global___TaskNode:
        """Information about the Task to execute in this node."""
        pass
    @property
    def workflow_node(self) -> global___WorkflowNode:
        """Information about the Workflow to execute in this mode."""
        pass
    @property
    def branch_node(self) -> global___BranchNode:
        """Information about the branch node to evaluate in this node."""
        pass
    def __init__(self,
        *,
        id : typing.Text = ...,
        metadata : typing.Optional[global___NodeMetadata] = ...,
        inputs : typing.Optional[typing.Iterable[flyteidl.core.literals_pb2.Binding]] = ...,
        upstream_node_ids : typing.Optional[typing.Iterable[typing.Text]] = ...,
        output_aliases : typing.Optional[typing.Iterable[global___Alias]] = ...,
        task_node : typing.Optional[global___TaskNode] = ...,
        workflow_node : typing.Optional[global___WorkflowNode] = ...,
        branch_node : typing.Optional[global___BranchNode] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"branch_node",b"branch_node",u"metadata",b"metadata",u"target",b"target",u"task_node",b"task_node",u"workflow_node",b"workflow_node"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"branch_node",b"branch_node",u"id",b"id",u"inputs",b"inputs",u"metadata",b"metadata",u"output_aliases",b"output_aliases",u"target",b"target",u"task_node",b"task_node",u"upstream_node_ids",b"upstream_node_ids",u"workflow_node",b"workflow_node"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal[u"target",b"target"]) -> typing.Optional[typing_extensions.Literal["task_node","workflow_node","branch_node"]]: ...
global___Node = Node

class WorkflowMetadata(google.protobuf.message.Message):
    """This is workflow layer metadata. These settings are only applicable to the workflow as a whole, and do not
    percolate down to child entities (like tasks) launched by the workflow.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class OnFailurePolicy(_OnFailurePolicy, metaclass=_OnFailurePolicyEnumTypeWrapper):
        """Failure Handling Strategy"""
        pass
    class _OnFailurePolicy:
        V = typing.NewType('V', builtins.int)
    class _OnFailurePolicyEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_OnFailurePolicy.V], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        FAIL_IMMEDIATELY = WorkflowMetadata.OnFailurePolicy.V(0)
        """FAIL_IMMEDIATELY instructs the system to fail as soon as a node fails in the workflow. It'll automatically
        abort all currently running nodes and clean up resources before finally marking the workflow executions as
        failed.
        """

        FAIL_AFTER_EXECUTABLE_NODES_COMPLETE = WorkflowMetadata.OnFailurePolicy.V(1)
        """FAIL_AFTER_EXECUTABLE_NODES_COMPLETE instructs the system to make as much progress as it can. The system will
        not alter the dependencies of the execution graph so any node that depend on the failed node will not be run.
        Other nodes that will be executed to completion before cleaning up resources and marking the workflow
        execution as failed.
        """


    FAIL_IMMEDIATELY = WorkflowMetadata.OnFailurePolicy.V(0)
    """FAIL_IMMEDIATELY instructs the system to fail as soon as a node fails in the workflow. It'll automatically
    abort all currently running nodes and clean up resources before finally marking the workflow executions as
    failed.
    """

    FAIL_AFTER_EXECUTABLE_NODES_COMPLETE = WorkflowMetadata.OnFailurePolicy.V(1)
    """FAIL_AFTER_EXECUTABLE_NODES_COMPLETE instructs the system to make as much progress as it can. The system will
    not alter the dependencies of the execution graph so any node that depend on the failed node will not be run.
    Other nodes that will be executed to completion before cleaning up resources and marking the workflow
    execution as failed.
    """


    QUALITY_OF_SERVICE_FIELD_NUMBER: builtins.int
    ON_FAILURE_FIELD_NUMBER: builtins.int
    @property
    def quality_of_service(self) -> flyteidl.core.execution_pb2.QualityOfService:
        """Indicates the runtime priority of workflow executions."""
        pass
    on_failure: global___WorkflowMetadata.OnFailurePolicy.V = ...
    """Defines how the system should behave when a failure is detected in the workflow execution."""

    def __init__(self,
        *,
        quality_of_service : typing.Optional[flyteidl.core.execution_pb2.QualityOfService] = ...,
        on_failure : global___WorkflowMetadata.OnFailurePolicy.V = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"quality_of_service",b"quality_of_service"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"on_failure",b"on_failure",u"quality_of_service",b"quality_of_service"]) -> None: ...
global___WorkflowMetadata = WorkflowMetadata

class WorkflowMetadataDefaults(google.protobuf.message.Message):
    """The difference between these settings and the WorkflowMetadata ones is that these are meant to be passed down to
    a workflow's underlying entities (like tasks). For instance, 'interruptible' has no meaning at the workflow layer, it
    is only relevant when a task executes. The settings here are the defaults that are passed to all nodes
    unless explicitly overridden at the node layer.
    If you are adding a setting that applies to both the Workflow itself, and everything underneath it, it should be
    added to both this object and the WorkflowMetadata object above.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    INTERRUPTIBLE_FIELD_NUMBER: builtins.int
    interruptible: builtins.bool = ...
    """Whether child nodes of the workflow are interruptible."""

    def __init__(self,
        *,
        interruptible : builtins.bool = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"interruptible",b"interruptible"]) -> None: ...
global___WorkflowMetadataDefaults = WorkflowMetadataDefaults

class WorkflowTemplate(google.protobuf.message.Message):
    """Flyte Workflow Structure that encapsulates task, branch and subworkflow nodes to form a statically analyzable,
    directed acyclic graph.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ID_FIELD_NUMBER: builtins.int
    METADATA_FIELD_NUMBER: builtins.int
    INTERFACE_FIELD_NUMBER: builtins.int
    NODES_FIELD_NUMBER: builtins.int
    OUTPUTS_FIELD_NUMBER: builtins.int
    FAILURE_NODE_FIELD_NUMBER: builtins.int
    METADATA_DEFAULTS_FIELD_NUMBER: builtins.int
    @property
    def id(self) -> flyteidl.core.identifier_pb2.Identifier:
        """A globally unique identifier for the workflow."""
        pass
    @property
    def metadata(self) -> global___WorkflowMetadata:
        """Extra metadata about the workflow."""
        pass
    @property
    def interface(self) -> flyteidl.core.interface_pb2.TypedInterface:
        """Defines a strongly typed interface for the Workflow. This can include some optional parameters."""
        pass
    @property
    def nodes(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Node]:
        """A list of nodes. In addition, "globals" is a special reserved node id that can be used to consume workflow inputs."""
        pass
    @property
    def outputs(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[flyteidl.core.literals_pb2.Binding]:
        """A list of output bindings that specify how to construct workflow outputs. Bindings can pull node outputs or
        specify literals. All workflow outputs specified in the interface field must be bound in order for the workflow
        to be validated. A workflow has an implicit dependency on all of its nodes to execute successfully in order to
        bind final outputs.
        Most of these outputs will be Binding's with a BindingData of type OutputReference.  That is, your workflow can
        just have an output of some constant (`Output(5)`), but usually, the workflow will be pulling
        outputs from the output of a task.
        """
        pass
    @property
    def failure_node(self) -> global___Node:
        """+optional A catch-all node. This node is executed whenever the execution engine determines the workflow has failed.
        The interface of this node must match the Workflow interface with an additional input named "error" of type
        pb.lyft.flyte.core.Error.
        """
        pass
    @property
    def metadata_defaults(self) -> global___WorkflowMetadataDefaults:
        """workflow defaults"""
        pass
    def __init__(self,
        *,
        id : typing.Optional[flyteidl.core.identifier_pb2.Identifier] = ...,
        metadata : typing.Optional[global___WorkflowMetadata] = ...,
        interface : typing.Optional[flyteidl.core.interface_pb2.TypedInterface] = ...,
        nodes : typing.Optional[typing.Iterable[global___Node]] = ...,
        outputs : typing.Optional[typing.Iterable[flyteidl.core.literals_pb2.Binding]] = ...,
        failure_node : typing.Optional[global___Node] = ...,
        metadata_defaults : typing.Optional[global___WorkflowMetadataDefaults] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"failure_node",b"failure_node",u"id",b"id",u"interface",b"interface",u"metadata",b"metadata",u"metadata_defaults",b"metadata_defaults"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"failure_node",b"failure_node",u"id",b"id",u"interface",b"interface",u"metadata",b"metadata",u"metadata_defaults",b"metadata_defaults",u"nodes",b"nodes",u"outputs",b"outputs"]) -> None: ...
global___WorkflowTemplate = WorkflowTemplate

class TaskNodeOverrides(google.protobuf.message.Message):
    """Optional task node overrides that will be applied at task execution time."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    RESOURCES_FIELD_NUMBER: builtins.int
    @property
    def resources(self) -> flyteidl.core.tasks_pb2.Resources:
        """A customizable interface to convey resources requested for a task container."""
        pass
    def __init__(self,
        *,
        resources : typing.Optional[flyteidl.core.tasks_pb2.Resources] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"resources",b"resources"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"resources",b"resources"]) -> None: ...
global___TaskNodeOverrides = TaskNodeOverrides
