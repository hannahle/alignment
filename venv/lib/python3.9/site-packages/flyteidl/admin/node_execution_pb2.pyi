"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import flyteidl.admin.common_pb2
import flyteidl.core.catalog_pb2
import flyteidl.core.compiler_pb2
import flyteidl.core.execution_pb2
import flyteidl.core.identifier_pb2
import flyteidl.core.literals_pb2
import google.protobuf.descriptor
import google.protobuf.duration_pb2
import google.protobuf.internal.containers
import google.protobuf.message
import google.protobuf.timestamp_pb2
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class NodeExecutionGetRequest(google.protobuf.message.Message):
    """A message used to fetch a single node execution entity.
    See :ref:`ref_flyteidl.admin.NodeExecution` for more details
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ID_FIELD_NUMBER: builtins.int
    @property
    def id(self) -> flyteidl.core.identifier_pb2.NodeExecutionIdentifier:
        """Uniquely identifies an individual node execution.
        +required
        """
        pass
    def __init__(self,
        *,
        id : typing.Optional[flyteidl.core.identifier_pb2.NodeExecutionIdentifier] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"id",b"id"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"id",b"id"]) -> None: ...
global___NodeExecutionGetRequest = NodeExecutionGetRequest

class NodeExecutionListRequest(google.protobuf.message.Message):
    """Represents a request structure to retrieve a list of node execution entities.
    See :ref:`ref_flyteidl.admin.NodeExecution` for more details
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    WORKFLOW_EXECUTION_ID_FIELD_NUMBER: builtins.int
    LIMIT_FIELD_NUMBER: builtins.int
    TOKEN_FIELD_NUMBER: builtins.int
    FILTERS_FIELD_NUMBER: builtins.int
    SORT_BY_FIELD_NUMBER: builtins.int
    UNIQUE_PARENT_ID_FIELD_NUMBER: builtins.int
    @property
    def workflow_execution_id(self) -> flyteidl.core.identifier_pb2.WorkflowExecutionIdentifier:
        """Indicates the workflow execution to filter by.
        +required
        """
        pass
    limit: builtins.int = ...
    """Indicates the number of resources to be returned.
    +required
    """

    token: typing.Text = ...
    """In the case of multiple pages of results, the, server-provided token can be used to fetch the next page
    in a query.
    +optional

    """

    filters: typing.Text = ...
    """Indicates a list of filters passed as string.
    More info on constructing filters : <Link>
    +optional
    """

    @property
    def sort_by(self) -> flyteidl.admin.common_pb2.Sort:
        """Sort ordering.
        +optional
        """
        pass
    unique_parent_id: typing.Text = ...
    """Unique identifier of the parent node in the execution
    +optional
    """

    def __init__(self,
        *,
        workflow_execution_id : typing.Optional[flyteidl.core.identifier_pb2.WorkflowExecutionIdentifier] = ...,
        limit : builtins.int = ...,
        token : typing.Text = ...,
        filters : typing.Text = ...,
        sort_by : typing.Optional[flyteidl.admin.common_pb2.Sort] = ...,
        unique_parent_id : typing.Text = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"sort_by",b"sort_by",u"workflow_execution_id",b"workflow_execution_id"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"filters",b"filters",u"limit",b"limit",u"sort_by",b"sort_by",u"token",b"token",u"unique_parent_id",b"unique_parent_id",u"workflow_execution_id",b"workflow_execution_id"]) -> None: ...
global___NodeExecutionListRequest = NodeExecutionListRequest

class NodeExecutionForTaskListRequest(google.protobuf.message.Message):
    """Represents a request structure to retrieve a list of node execution entities launched by a specific task.
    This can arise when a task yields a subworkflow.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    TASK_EXECUTION_ID_FIELD_NUMBER: builtins.int
    LIMIT_FIELD_NUMBER: builtins.int
    TOKEN_FIELD_NUMBER: builtins.int
    FILTERS_FIELD_NUMBER: builtins.int
    SORT_BY_FIELD_NUMBER: builtins.int
    @property
    def task_execution_id(self) -> flyteidl.core.identifier_pb2.TaskExecutionIdentifier:
        """Indicates the node execution to filter by.
        +required
        """
        pass
    limit: builtins.int = ...
    """Indicates the number of resources to be returned.
    +required
    """

    token: typing.Text = ...
    """In the case of multiple pages of results, the, server-provided token can be used to fetch the next page
    in a query.
    +optional
    """

    filters: typing.Text = ...
    """Indicates a list of filters passed as string.
    More info on constructing filters : <Link>
    +optional
    """

    @property
    def sort_by(self) -> flyteidl.admin.common_pb2.Sort:
        """Sort ordering.
        +optional
        """
        pass
    def __init__(self,
        *,
        task_execution_id : typing.Optional[flyteidl.core.identifier_pb2.TaskExecutionIdentifier] = ...,
        limit : builtins.int = ...,
        token : typing.Text = ...,
        filters : typing.Text = ...,
        sort_by : typing.Optional[flyteidl.admin.common_pb2.Sort] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"sort_by",b"sort_by",u"task_execution_id",b"task_execution_id"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"filters",b"filters",u"limit",b"limit",u"sort_by",b"sort_by",u"task_execution_id",b"task_execution_id",u"token",b"token"]) -> None: ...
global___NodeExecutionForTaskListRequest = NodeExecutionForTaskListRequest

class NodeExecution(google.protobuf.message.Message):
    """Encapsulates all details for a single node execution entity.
    A node represents a component in the overall workflow graph. A node launch a task, multiple tasks, an entire nested
    sub-workflow, or even a separate child-workflow execution.
    The same task can be called repeatedly in a single workflow but each node is unique.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ID_FIELD_NUMBER: builtins.int
    INPUT_URI_FIELD_NUMBER: builtins.int
    CLOSURE_FIELD_NUMBER: builtins.int
    METADATA_FIELD_NUMBER: builtins.int
    @property
    def id(self) -> flyteidl.core.identifier_pb2.NodeExecutionIdentifier:
        """Uniquely identifies an individual node execution."""
        pass
    input_uri: typing.Text = ...
    """Path to remote data store where input blob is stored."""

    @property
    def closure(self) -> global___NodeExecutionClosure:
        """Computed results associated with this node execution."""
        pass
    @property
    def metadata(self) -> global___NodeExecutionMetaData:
        """Metadata for Node Execution"""
        pass
    def __init__(self,
        *,
        id : typing.Optional[flyteidl.core.identifier_pb2.NodeExecutionIdentifier] = ...,
        input_uri : typing.Text = ...,
        closure : typing.Optional[global___NodeExecutionClosure] = ...,
        metadata : typing.Optional[global___NodeExecutionMetaData] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"closure",b"closure",u"id",b"id",u"metadata",b"metadata"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"closure",b"closure",u"id",b"id",u"input_uri",b"input_uri",u"metadata",b"metadata"]) -> None: ...
global___NodeExecution = NodeExecution

class NodeExecutionMetaData(google.protobuf.message.Message):
    """Represents additional attributes related to a Node Execution"""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    RETRY_GROUP_FIELD_NUMBER: builtins.int
    IS_PARENT_NODE_FIELD_NUMBER: builtins.int
    SPEC_NODE_ID_FIELD_NUMBER: builtins.int
    retry_group: typing.Text = ...
    """Node executions are grouped depending on retries of the parent
    Retry group is unique within the context of a parent node.
    """

    is_parent_node: builtins.bool = ...
    """Boolean flag indicating if the node has child nodes under it
    This can be true when a node contains a dynamic workflow which then produces
    child nodes.
    """

    spec_node_id: typing.Text = ...
    """Node id of the node in the original workflow
    This maps to value of WorkflowTemplate.nodes[X].id
    """

    def __init__(self,
        *,
        retry_group : typing.Text = ...,
        is_parent_node : builtins.bool = ...,
        spec_node_id : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"is_parent_node",b"is_parent_node",u"retry_group",b"retry_group",u"spec_node_id",b"spec_node_id"]) -> None: ...
global___NodeExecutionMetaData = NodeExecutionMetaData

class NodeExecutionList(google.protobuf.message.Message):
    """Request structure to retrieve a list of node execution entities.
    See :ref:`ref_flyteidl.admin.NodeExecution` for more details
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    NODE_EXECUTIONS_FIELD_NUMBER: builtins.int
    TOKEN_FIELD_NUMBER: builtins.int
    @property
    def node_executions(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___NodeExecution]: ...
    token: typing.Text = ...
    """In the case of multiple pages of results, the server-provided token can be used to fetch the next page
    in a query. If there are no more results, this value will be empty.
    """

    def __init__(self,
        *,
        node_executions : typing.Optional[typing.Iterable[global___NodeExecution]] = ...,
        token : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"node_executions",b"node_executions",u"token",b"token"]) -> None: ...
global___NodeExecutionList = NodeExecutionList

class NodeExecutionClosure(google.protobuf.message.Message):
    """Container for node execution details and results."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    OUTPUT_URI_FIELD_NUMBER: builtins.int
    ERROR_FIELD_NUMBER: builtins.int
    OUTPUT_DATA_FIELD_NUMBER: builtins.int
    PHASE_FIELD_NUMBER: builtins.int
    STARTED_AT_FIELD_NUMBER: builtins.int
    DURATION_FIELD_NUMBER: builtins.int
    CREATED_AT_FIELD_NUMBER: builtins.int
    UPDATED_AT_FIELD_NUMBER: builtins.int
    WORKFLOW_NODE_METADATA_FIELD_NUMBER: builtins.int
    TASK_NODE_METADATA_FIELD_NUMBER: builtins.int
    output_uri: typing.Text = ...
    """Links to a remotely stored, serialized core.LiteralMap of node execution outputs."""

    @property
    def error(self) -> flyteidl.core.execution_pb2.ExecutionError:
        """Error information for the Node"""
        pass
    @property
    def output_data(self) -> flyteidl.core.literals_pb2.LiteralMap:
        """Raw output data produced by this node execution."""
        pass
    phase: flyteidl.core.execution_pb2.NodeExecution.Phase.V = ...
    """The last recorded phase for this node execution."""

    @property
    def started_at(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Time at which the node execution began running."""
        pass
    @property
    def duration(self) -> google.protobuf.duration_pb2.Duration:
        """The amount of time the node execution spent running."""
        pass
    @property
    def created_at(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Time at which the node execution was created."""
        pass
    @property
    def updated_at(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Time at which the node execution was last updated."""
        pass
    @property
    def workflow_node_metadata(self) -> global___WorkflowNodeMetadata: ...
    @property
    def task_node_metadata(self) -> global___TaskNodeMetadata: ...
    def __init__(self,
        *,
        output_uri : typing.Text = ...,
        error : typing.Optional[flyteidl.core.execution_pb2.ExecutionError] = ...,
        output_data : typing.Optional[flyteidl.core.literals_pb2.LiteralMap] = ...,
        phase : flyteidl.core.execution_pb2.NodeExecution.Phase.V = ...,
        started_at : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        duration : typing.Optional[google.protobuf.duration_pb2.Duration] = ...,
        created_at : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        updated_at : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        workflow_node_metadata : typing.Optional[global___WorkflowNodeMetadata] = ...,
        task_node_metadata : typing.Optional[global___TaskNodeMetadata] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"created_at",b"created_at",u"duration",b"duration",u"error",b"error",u"output_data",b"output_data",u"output_result",b"output_result",u"output_uri",b"output_uri",u"started_at",b"started_at",u"target_metadata",b"target_metadata",u"task_node_metadata",b"task_node_metadata",u"updated_at",b"updated_at",u"workflow_node_metadata",b"workflow_node_metadata"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"created_at",b"created_at",u"duration",b"duration",u"error",b"error",u"output_data",b"output_data",u"output_result",b"output_result",u"output_uri",b"output_uri",u"phase",b"phase",u"started_at",b"started_at",u"target_metadata",b"target_metadata",u"task_node_metadata",b"task_node_metadata",u"updated_at",b"updated_at",u"workflow_node_metadata",b"workflow_node_metadata"]) -> None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal[u"output_result",b"output_result"]) -> typing.Optional[typing_extensions.Literal["output_uri","error","output_data"]]: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal[u"target_metadata",b"target_metadata"]) -> typing.Optional[typing_extensions.Literal["workflow_node_metadata","task_node_metadata"]]: ...
global___NodeExecutionClosure = NodeExecutionClosure

class WorkflowNodeMetadata(google.protobuf.message.Message):
    """Metadata for a WorkflowNode"""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    EXECUTIONID_FIELD_NUMBER: builtins.int
    @property
    def executionId(self) -> flyteidl.core.identifier_pb2.WorkflowExecutionIdentifier:
        """The identifier for a workflow execution launched by a node."""
        pass
    def __init__(self,
        *,
        executionId : typing.Optional[flyteidl.core.identifier_pb2.WorkflowExecutionIdentifier] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"executionId",b"executionId"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"executionId",b"executionId"]) -> None: ...
global___WorkflowNodeMetadata = WorkflowNodeMetadata

class TaskNodeMetadata(google.protobuf.message.Message):
    """Metadata for the case in which the node is a TaskNode"""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    CACHE_STATUS_FIELD_NUMBER: builtins.int
    CATALOG_KEY_FIELD_NUMBER: builtins.int
    cache_status: flyteidl.core.catalog_pb2.CatalogCacheStatus.V = ...
    """Captures the status of caching for this execution."""

    @property
    def catalog_key(self) -> flyteidl.core.catalog_pb2.CatalogMetadata:
        """This structure carries the catalog artifact information"""
        pass
    def __init__(self,
        *,
        cache_status : flyteidl.core.catalog_pb2.CatalogCacheStatus.V = ...,
        catalog_key : typing.Optional[flyteidl.core.catalog_pb2.CatalogMetadata] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"catalog_key",b"catalog_key"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"cache_status",b"cache_status",u"catalog_key",b"catalog_key"]) -> None: ...
global___TaskNodeMetadata = TaskNodeMetadata

class DynamicWorkflowNodeMetadata(google.protobuf.message.Message):
    """For dynamic workflow nodes we capture information about the dynamic workflow definition that gets generated."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ID_FIELD_NUMBER: builtins.int
    COMPILED_WORKFLOW_FIELD_NUMBER: builtins.int
    @property
    def id(self) -> flyteidl.core.identifier_pb2.Identifier:
        """id represents the unique identifier of the workflow."""
        pass
    @property
    def compiled_workflow(self) -> flyteidl.core.compiler_pb2.CompiledWorkflowClosure:
        """Represents the compiled representation of the embedded dynamic workflow."""
        pass
    def __init__(self,
        *,
        id : typing.Optional[flyteidl.core.identifier_pb2.Identifier] = ...,
        compiled_workflow : typing.Optional[flyteidl.core.compiler_pb2.CompiledWorkflowClosure] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"compiled_workflow",b"compiled_workflow",u"id",b"id"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"compiled_workflow",b"compiled_workflow",u"id",b"id"]) -> None: ...
global___DynamicWorkflowNodeMetadata = DynamicWorkflowNodeMetadata

class NodeExecutionGetDataRequest(google.protobuf.message.Message):
    """Request structure to fetch inputs and output for a node execution.
    By default, these are not returned in :ref:`ref_flyteidl.admin.NodeExecutionGetRequest`
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ID_FIELD_NUMBER: builtins.int
    @property
    def id(self) -> flyteidl.core.identifier_pb2.NodeExecutionIdentifier:
        """The identifier of the node execution for which to fetch inputs and outputs."""
        pass
    def __init__(self,
        *,
        id : typing.Optional[flyteidl.core.identifier_pb2.NodeExecutionIdentifier] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"id",b"id"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"id",b"id"]) -> None: ...
global___NodeExecutionGetDataRequest = NodeExecutionGetDataRequest

class NodeExecutionGetDataResponse(google.protobuf.message.Message):
    """Response structure for NodeExecutionGetDataRequest which contains inputs and outputs for a node execution."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    INPUTS_FIELD_NUMBER: builtins.int
    OUTPUTS_FIELD_NUMBER: builtins.int
    FULL_INPUTS_FIELD_NUMBER: builtins.int
    FULL_OUTPUTS_FIELD_NUMBER: builtins.int
    DYNAMIC_WORKFLOW_FIELD_NUMBER: builtins.int
    @property
    def inputs(self) -> flyteidl.admin.common_pb2.UrlBlob:
        """Signed url to fetch a core.LiteralMap of node execution inputs.
        Deprecated: Please use full_inputs instead.
        """
        pass
    @property
    def outputs(self) -> flyteidl.admin.common_pb2.UrlBlob:
        """Signed url to fetch a core.LiteralMap of node execution outputs.
        Deprecated: Please use full_outputs instead.
        """
        pass
    @property
    def full_inputs(self) -> flyteidl.core.literals_pb2.LiteralMap:
        """Full_inputs will only be populated if they are under a configured size threshold."""
        pass
    @property
    def full_outputs(self) -> flyteidl.core.literals_pb2.LiteralMap:
        """Full_outputs will only be populated if they are under a configured size threshold."""
        pass
    @property
    def dynamic_workflow(self) -> global___DynamicWorkflowNodeMetadata:
        """Optional Workflow closure for a dynamically generated workflow, in the case this node yields a dynamic workflow we return its structure here."""
        pass
    def __init__(self,
        *,
        inputs : typing.Optional[flyteidl.admin.common_pb2.UrlBlob] = ...,
        outputs : typing.Optional[flyteidl.admin.common_pb2.UrlBlob] = ...,
        full_inputs : typing.Optional[flyteidl.core.literals_pb2.LiteralMap] = ...,
        full_outputs : typing.Optional[flyteidl.core.literals_pb2.LiteralMap] = ...,
        dynamic_workflow : typing.Optional[global___DynamicWorkflowNodeMetadata] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal[u"dynamic_workflow",b"dynamic_workflow",u"full_inputs",b"full_inputs",u"full_outputs",b"full_outputs",u"inputs",b"inputs",u"outputs",b"outputs"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal[u"dynamic_workflow",b"dynamic_workflow",u"full_inputs",b"full_inputs",u"full_outputs",b"full_outputs",u"inputs",b"inputs",u"outputs",b"outputs"]) -> None: ...
global___NodeExecutionGetDataResponse = NodeExecutionGetDataResponse
